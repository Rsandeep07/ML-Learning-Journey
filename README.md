# ML-Learning-Journey  
Daily hands-on notebooks exploring **data preprocessing**, **EDA**, **categorical encoding**, **model building**, and **performance analysis**.

---

## ðŸ“Œ About This Repository  
This repository documents my **daily learning journey in Machine Learning**.  
Each notebook focuses on one concept or dataset, combining both **theory and practical implementation** using Python libraries such as:

- pandas  
- numpy  
- matplotlib  
- scikit-learn  

---

## ðŸŽ¯ Core Skills Covered
- Exploratory Data Analysis (EDA)
- Data Cleaning & Preprocessing
- Feature Engineering
- Handling Categorical & Numerical Data
- Trainâ€“Test Split & Standardization
- Supervised Learning Models
- Model Evaluation & Hyperparameter Tuning
- Real-world ML Pipelines

---

# ðŸ“˜ Daily Notes

---

# ðŸ”¹ Day 1 â€” Data Cleaning & Exploratory Data Analysis (EDA)

### âœ” Topics Covered
- Introduction to dataset  
- Handling missing values  
- Basic EDA  
- Understanding dataset structure:
  - `.shape`
  - `.info()`
  - `.describe()`
- Univariate & bivariate analysis  
- Cleaning inconsistent entries  
- Visualizations:
  - histograms  
  - countplots  
  - scatterplots  

---

# ðŸ”¹ Day 2 â€” Extended EDA & Preprocessing

### âœ” Topics Covered
- Outlier detection:
  - IQR  
  - Boxplots  
- Treating/removing outliers  
- Correlation analysis  
- Heatmap visualization  
- Advanced feature understanding  
- Dataset preparation for ML models  

---

# ðŸ”¹ Day 3 â€” Trainâ€“Test Split, Feature Scaling & Model Evaluation

### âœ” Steps Performed

### **1. Loading the Dataset**
- Loaded IRIS dataset using `load_iris()`  
- Converted features + target to DataFrame  

### **2. Basic EDA**
- `.head()`, unique targets, feature distributions  

### **3. Trainâ€“Test Split**
```python
from sklearn.model_selection import train_test_split

### **4. Feature Scaling**
from sklearn.preprocessing import StandardScaler


### **5. Models Used**
- Logistic Regression
- KNN
- Decision Tree / Random Forest

### **6. Model Evaluation**
- Train accuracy
- Test accuracy

### **Final Day 3 Requirement**
- | Train Accuracy â€“ Test Accuracy | <= 5%

# ðŸ”¹ Day 4 â€” Categorical Encoding & One-Hot Encoding

(Starts from â€œCategorical Encoding and One Hot Encodingâ€)
- Why Encoding is Needed?
- ML models work only with numbers, not text
- Categorical features must be encoded

# Label Encoding
- Converts categories â†’ numbers.
```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['column'] = le.fit_transform(df['column'])

# One-Hot Encoding
pd.get_dummies(df, drop_first=True)



```Using Scikit-Learn
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(drop='first', sparse=False)
encoded = ohe.fit_transform(df[['column']])


# Handling Encoded Data
- Convert encoded arrays to DataFrame
- Merge with original data
- Drop original categorical columns
- Final ML-ready DataFrame created

# pdated ML Pipeline After Day 4
  - Encode categorical variables
  - Trainâ€“test split
  - Standardize numerical features
  - Train ML model
  - Evaluate performance
  - Compare metrics with Day 3

# Repository Structure
ML-Learning-Journey/
â”‚
â”œâ”€â”€ Day1.ipynb
â”œâ”€â”€ Day2.ipynb
â”œâ”€â”€ Day3.ipynb
â”œâ”€â”€ Day4.ipynb
â””â”€â”€ README.md
