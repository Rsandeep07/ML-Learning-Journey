{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693f4d85-3bd5-41f8-8562-1db0543e7844",
   "metadata": {},
   "source": [
    "# ðŸ“˜ ML Learning Journey â€” Model Evaluation & Selection\n",
    "\n",
    "## RÂ², Adjusted RÂ², Generalization & Model Selection\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Classification vs Regression Metrics (Quick Context)\n",
    "\n",
    "### Classification Metrics\n",
    "- **Accuracy** works well for **balanced datasets**\n",
    "- For **imbalanced datasets**, accuracy is misleading\n",
    "\n",
    "Better metrics for imbalanced data:\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Balanced Accuracy\n",
    "\n",
    "**F1 Score**\n",
    "- Harmonic mean of Precision and Recall\n",
    "- Penalizes extreme values\n",
    "- Treats FP and FN equally\n",
    "- Useful when both error types matter\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Regression Metrics Overview\n",
    "\n",
    "Regression problems deal with **continuous target variables**.\n",
    "\n",
    "### Common Regression Metrics\n",
    "- **MAE (Mean Absolute Error)**  \n",
    "  Average absolute difference between actual and predicted values\n",
    "\n",
    "- **MSE (Mean Squared Error)**  \n",
    "  Penalizes large errors more heavily\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**  \n",
    "  Same units as target variable, more interpretable\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why RÂ² (R-Squared)?\n",
    "\n",
    "Error-based metrics alone do not explain **how well a model explains data variability**.\n",
    "\n",
    "**RÂ² measures the proportion of variance in the target variable explained by the model.**\n",
    "\n",
    "### Interpretation\n",
    "- RÂ² = 1 â†’ Perfect model\n",
    "- RÂ² = 0 â†’ Model explains nothing\n",
    "- RÂ² < 0 â†’ Worse than mean model\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Baseline: Mean Model\n",
    "\n",
    "Before evaluating a regression model, consider a **mean model**:\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\bar{y}\n",
    "\\]\n",
    "\n",
    "This acts as a baseline for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Error Decomposition\n",
    "\n",
    "### Total Sum of Squares (TSS)\n",
    "\\[\n",
    "TSS = \\sum (y_i - \\bar{y})^2\n",
    "\\]\n",
    "\n",
    "### Residual Sum of Squares (RSS)\n",
    "\\[\n",
    "RSS = \\sum (y_i - \\hat{y}_i)^2\n",
    "\\]\n",
    "\n",
    "### Explained Variance\n",
    "\\[\n",
    "Explained = TSS - RSS\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 6. RÂ² Formula\n",
    "\n",
    "\\[\n",
    "R^2 = 1 - \\frac{RSS}{TSS}\n",
    "\\]\n",
    "\n",
    "### Meaning\n",
    "- Measures fraction of variance explained by the model\n",
    "- Example:  \n",
    "  RÂ² = 0.8 â†’ 80% of variance explained\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Limitation of RÂ²\n",
    "\n",
    "- RÂ² **always increases** when more features are added\n",
    "- Even if the new features are not useful\n",
    "- Leads to **overfitting**\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Adjusted RÂ²\n",
    "\n",
    "Adjusted RÂ² penalizes unnecessary features.\n",
    "\n",
    "### Formula\n",
    "\\[\n",
    "\\text{Adjusted } R^2 = 1 - (1 - R^2)\\frac{n - 1}{n - k - 1}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `n` = number of observations\n",
    "- `k` = number of features\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Why Adjusted RÂ² is Better\n",
    "\n",
    "- Increases only if new feature adds real value\n",
    "- Decreases if feature adds noise\n",
    "- Useful for **model comparison**\n",
    "\n",
    "**Rule of Thumb**\n",
    "- Use RÂ² for explanation\n",
    "- Use Adjusted RÂ² for model selection\n",
    "\n",
    "---\n",
    "\n",
    "## 10. When Can RÂ² Be Negative?\n",
    "\n",
    "- When model performs worse than the mean model\n",
    "- Often due to:\n",
    "  - Poor feature selection\n",
    "  - Wrong model choice\n",
    "  - Non-linear data with linear model\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Model Evaluation Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267d205-12d3-4492-8ec1-aea7416bfa6f",
   "metadata": {},
   "source": [
    "Features (X)  \n",
    "â†“  \n",
    "Model  \n",
    "â†“  \n",
    "Predictions (Å·)  \n",
    "â†“  \n",
    "Compare Å· vs y  \n",
    "â†“  \n",
    "Metrics (RÂ², Adj RÂ², MAE, RMSE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4392e4a-04e3-488e-80ca-5d202163ab1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T13:22:07.467352Z",
     "iopub.status.busy": "2026-01-02T13:22:07.466337Z",
     "iopub.status.idle": "2026-01-02T13:22:07.480510Z",
     "shell.execute_reply": "2026-01-02T13:22:07.479494Z",
     "shell.execute_reply.started": "2026-01-02T13:22:07.467352Z"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 12. Training vs Model\n",
    "\n",
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d9353-08dd-4ff5-8c43-2038f09af5aa",
   "metadata": {},
   "source": [
    "#### Data â†’ ML Algorithm â†’ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcab0a-0562-49af-af85-0a22bbb62dd2",
   "metadata": {},
   "source": [
    "\n",
    "- Algorithm + hyperparameters define the model\n",
    "- Different hyperparameters â†’ different models\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Hyperparameter Tuning\n",
    "\n",
    "Goal:\n",
    "- Find optimal hyperparameters\n",
    "- Maximize performance\n",
    "- Avoid overfitting\n",
    "\n",
    "Example (KNN):\n",
    "- k\n",
    "- distance metric\n",
    "- weights\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Memorization vs Generalization\n",
    "\n",
    "- **Memorization**\n",
    "  - Very good training performance\n",
    "  - Poor unseen data performance\n",
    "\n",
    "- **Generalization**\n",
    "  - Good performance on both train and unseen data\n",
    "  - True goal of Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## 15. Testing Generalization\n",
    "\n",
    "### Cross Validation\n",
    "- Split data into multiple folds\n",
    "- Evaluate on unseen data\n",
    "\n",
    "### Learning Curves\n",
    "- Compare training vs validation error\n",
    "- Detect overfitting and underfitting\n",
    "\n",
    "---\n",
    "\n",
    "## 16. Statistical Perspective\n",
    "\n",
    "Machine Learning follows **inferential thinking**:\n",
    "\n",
    "1. Draw a representative sample\n",
    "2. Analyze the sample\n",
    "3. Extract patterns\n",
    "4. Apply findings to population with confidence\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Key Takeaways\n",
    "\n",
    "- RÂ² explains variance\n",
    "- Adjusted RÂ² helps in feature selection\n",
    "- More features â‰  better model\n",
    "- Model selection is as important as accuracy\n",
    "- Generalization is the ultimate goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5750d05-ea9a-4236-947e-2fce06339737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
