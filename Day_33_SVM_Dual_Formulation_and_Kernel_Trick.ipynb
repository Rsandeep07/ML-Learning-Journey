{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595e7101-a1e5-4e04-a61b-0ec98df08b9f",
   "metadata": {},
   "source": [
    "# Day 33 — SVM Dual Formulation & Kernel Trick\n",
    "\n",
    "This notebook is part of my **Machine Learning Learning Journey** and focuses on the\n",
    "**optimization and kernel perspective of Support Vector Machines (SVM).**\n",
    "\n",
    "This session builds on SVM foundations and introduces:\n",
    "- Primal vs Dual formulation\n",
    "- Support vectors from dual view\n",
    "- Soft-margin optimization\n",
    "- Hinge loss\n",
    "- Kernel trick and feature mapping\n",
    "- Popular kernels (Linear, Polynomial, RBF, Sigmoid)\n",
    "- XOR problem and non-linear separability\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4337c-6987-4d0e-9671-5b41f8eb4583",
   "metadata": {},
   "source": [
    "## 1. Recap: SVM Decision Function\n",
    "\n",
    "Hyperplane:\n",
    "\\[\n",
    "w^T x + b = 0\n",
    "\\]\n",
    "\n",
    "Classification rule:\n",
    "\\[\n",
    "y_i (w^T x_i + b) \\ge 1\n",
    "\\]\n",
    "\n",
    "Margin:\n",
    "\\[\n",
    "\\frac{2}{\\|w\\|}\n",
    "\\]\n",
    "\n",
    "Goal:\n",
    "Maximize margin ↔ minimize \\( \\|w\\| \\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb11b2-f334-4d8f-88f4-614ea82028b2",
   "metadata": {},
   "source": [
    "## 2. Hard Margin SVM (Primal Form)\n",
    "\n",
    "Optimization problem:\n",
    "\n",
    "\\[\n",
    "\\min \\frac{1}{2}\\|w\\|^2\n",
    "\\]\n",
    "\n",
    "Subject to:\n",
    "\\[\n",
    "y_i (w^T x_i + b) \\ge 1\n",
    "\\]\n",
    "\n",
    "Assumes:\n",
    "- Perfect separability\n",
    "- No noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32baa2-cf32-49c2-a43e-7a4723cd14ca",
   "metadata": {},
   "source": [
    "## 3. Lagrangian for Constrained Optimization\n",
    "\n",
    "Introduce multipliers \\( \\lambda_i \\):\n",
    "\n",
    "\\[\n",
    "L(w,b,\\lambda) = \\frac{1}{2}\\|w\\|^2 + \\sum \\lambda_i(1 - y_i(w^T x_i + b))\n",
    "\\]\n",
    "\n",
    "Conditions:\n",
    "\\[\n",
    "\\lambda_i \\ge 0\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d91a65-2b7f-41dc-a8a8-285871b1c6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T12:54:28.867824Z",
     "iopub.status.busy": "2026-01-31T12:54:28.867824Z",
     "iopub.status.idle": "2026-01-31T12:54:28.890421Z",
     "shell.execute_reply": "2026-01-31T12:54:28.890038Z",
     "shell.execute_reply.started": "2026-01-31T12:54:28.867824Z"
    }
   },
   "source": [
    "## 4. Dual Formulation\n",
    "\n",
    "Maximize:\n",
    "\n",
    "\\[\n",
    "\\sum \\lambda_i - \\frac{1}{2} \\sum\\sum \\lambda_i\\lambda_j y_i y_j (x_i^T x_j)\n",
    "\\]\n",
    "\n",
    "Subject to:\n",
    "\\[\n",
    "\\sum \\lambda_i y_i = 0\n",
    "\\]\n",
    "\\[\n",
    "\\lambda_i \\ge 0\n",
    "\\]\n",
    "\n",
    "Key insight:\n",
    "Dual depends only on **dot products**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856c5de-0ed7-44e4-bc57-2fb630af8241",
   "metadata": {},
   "source": [
    "## 5. Support Vectors\n",
    "\n",
    "Only points with:\n",
    "\\[\n",
    "\\lambda_i > 0\n",
    "\\]\n",
    "\n",
    "are support vectors.\n",
    "\n",
    "They:\n",
    "- Define the decision boundary\n",
    "- Control the margin\n",
    "- Ignore far-away points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a72a6-7840-4c7d-95c9-2644e2dd93f1",
   "metadata": {},
   "source": [
    "## 6. Soft Margin SVM\n",
    "\n",
    "Introduce slack variables \\( \\xi_i \\):\n",
    "\n",
    "\\[\n",
    "y_i(w^T x_i + b) \\ge 1 - \\xi_i\n",
    "\\]\n",
    "\n",
    "Objective:\n",
    "\n",
    "\\[\n",
    "\\min \\frac{1}{2}\\|w\\|^2 + C\\sum \\xi_i\n",
    "\\]\n",
    "\n",
    "C controls:\n",
    "- Margin vs misclassification tradeoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90494cf-4a78-4b3d-9b94-17a82bffd1ff",
   "metadata": {},
   "source": [
    "## 7. Hinge Loss\n",
    "\n",
    "\\[\n",
    "\\max(0, 1 - y_i(w^T x_i))\n",
    "\\]\n",
    "\n",
    "Loss behavior:\n",
    "- 0 → correct classification\n",
    "- >0 → margin violation\n",
    "- Large → misclassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd514b-5971-4eb6-a53f-eaccbbe78920",
   "metadata": {},
   "source": [
    "## 8. Kernel Trick Motivation\n",
    "\n",
    "Some data is not linearly separable.\n",
    "\n",
    "Idea:\n",
    "Map data to higher dimension:\n",
    "\\[\n",
    "\\phi(x)\n",
    "\\]\n",
    "\n",
    "But computing \\(\\phi(x)\\) explicitly is expensive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290571d-fc41-48fe-80dc-370d550806ca",
   "metadata": {},
   "source": [
    "## 9. Kernel Trick\n",
    "\n",
    "Instead of:\n",
    "\\[\n",
    "\\phi(x_i)^T \\phi(x_j)\n",
    "\\]\n",
    "\n",
    "Use kernel:\n",
    "\\[\n",
    "K(x_i,x_j)\n",
    "\\]\n",
    "\n",
    "Compute dot product in high-dim space\n",
    "without explicit transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f28635-3ff2-47dd-808a-fcaad0d7174d",
   "metadata": {},
   "source": [
    "## 10. Common Kernels\n",
    "\n",
    "### Linear\n",
    "\\[\n",
    "K(x_i,x_j)=x_i^Tx_j\n",
    "\\]\n",
    "\n",
    "### Polynomial\n",
    "\\[\n",
    "(x_i^Tx_j + c)^d\n",
    "\\]\n",
    "\n",
    "### RBF (Gaussian)\n",
    "\\[\n",
    "\\exp(-\\gamma\\|x_i-x_j\\|^2)\n",
    "\\]\n",
    "\n",
    "### Sigmoid\n",
    "\\[\n",
    "\\tanh(ax_i^Tx_j + c)\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc6d45-f471-41a3-a2a2-c89109e01dfe",
   "metadata": {},
   "source": [
    "## 11. XOR Problem\n",
    "\n",
    "XOR is not linearly separable in 2D.\n",
    "\n",
    "Solution:\n",
    "Map to higher dimension.\n",
    "\n",
    "Polynomial or RBF kernel can separate XOR.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d0a4b-1133-4c5c-b2ad-9f87b3ca18ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "835cc45b-9c75-410d-8993-3f18f324a3f2",
   "metadata": {},
   "source": [
    "## 13. Multiclass Classification in SVM\n",
    "\n",
    "Binary SVM extended to multiclass using:\n",
    "- One-vs-One (OvO)\n",
    "- One-vs-Rest (OvR / OvA)\n",
    "\n",
    "OvO:\n",
    "- Train classifier for every class pair\n",
    "\n",
    "OvR:\n",
    "- Train one classifier per class vs all others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92972dff-13e2-4f63-b267-d3bc04257bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T12:58:07.821005Z",
     "iopub.status.busy": "2026-01-31T12:58:07.821005Z",
     "iopub.status.idle": "2026-01-31T12:58:11.165073Z",
     "shell.execute_reply": "2026-01-31T12:58:11.163791Z",
     "shell.execute_reply.started": "2026-01-31T12:58:07.821005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = SVC(kernel=\"linear\", C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80638a75-28f7-406a-a795-21a96a844bde",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- SVM is a margin-based classifier\n",
    "- Focuses on boundary points (support vectors)\n",
    "- Maximizes margin instead of probability\n",
    "- Hard Margin works only for separable data\n",
    "- Soft Margin handles noise and outliers\n",
    "- Regularization parameter C controls bias–variance\n",
    "- SVM forms the foundation for kernel methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9f764-d8b7-4547-8d0c-d4ec8c32c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
