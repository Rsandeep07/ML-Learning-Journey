{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342ecdec-4386-48dc-b3b2-ff7f3fffa9ba",
   "metadata": {},
   "source": [
    "### Day 24 — Advanced Hyperparameter Tuning (Bayesian Optimization & Optuna)\n",
    "\n",
    "This notebook documents **Day 24** of my Machine Learning learning journey.\n",
    "The focus of this day is on **advanced hyperparameter tuning strategies**, moving\n",
    "beyond classical Grid and Random Search toward **Sequential / Bayesian Optimization**\n",
    "using **Optuna**.\n",
    "\n",
    "This day builds directly on concepts of **generalization**, **bias–variance tradeoff**,\n",
    "and **cross-validation** learned in previous days.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d78c07-c216-43c5-beeb-725bbeba0289",
   "metadata": {},
   "source": [
    "## 1. Recap: Generalization & Cross Validation\n",
    "\n",
    "### What is Generalization?\n",
    "- Generalization refers to a model’s ability to perform well on **unseen (test) data**\n",
    "- A model that performs well only on training data is **memorizing**, not learning\n",
    "\n",
    "### Memorization vs Generalization\n",
    "- Memorization → Overfitting\n",
    "- Generalization → Balanced bias and variance\n",
    "\n",
    "### Role of Cross Validation\n",
    "- Cross validation helps estimate **true generalization performance**\n",
    "- Prevents tuning decisions based on a single train–test split\n",
    "- Helps detect:\n",
    "  - Overfitting\n",
    "  - Underfitting\n",
    "  - High variance models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a9adf-1660-4ccc-a662-0aa61514be02",
   "metadata": {},
   "source": [
    "## 2. Overfitting, Underfitting & Bias–Variance Tradeoff\n",
    "\n",
    "### Overfitting\n",
    "- Low bias, high variance\n",
    "- Very complex model\n",
    "- Large gap between training and validation/test performance\n",
    "\n",
    "### Underfitting\n",
    "- High bias, low variance\n",
    "- Very simple model\n",
    "- Poor performance on both training and test data\n",
    "\n",
    "### Bias–Variance Tradeoff\n",
    "- Increasing model complexity:\n",
    "  - Decreases bias\n",
    "  - Increases variance\n",
    "- Decreasing model complexity:\n",
    "  - Increases bias\n",
    "  - Decreases variance\n",
    "- Goal: **optimal balance for best generalization**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5efe31-68cc-4cb8-b46d-c3c42103c7a7",
   "metadata": {},
   "source": [
    "## 3. Ways to Improve Model Generalization\n",
    "\n",
    "The notebook discusses three major approaches:\n",
    "\n",
    "1. **Cross Validation**\n",
    "   - Reliable estimation of model performance\n",
    "   - Helps compare models fairly\n",
    "\n",
    "2. **Regularization**\n",
    "   - Penalizes overly complex models\n",
    "   - Examples:\n",
    "     - L1 (Lasso)\n",
    "     - L2 (Ridge)\n",
    "     - Elastic Net\n",
    "\n",
    "3. **Ensemble Methods**\n",
    "   - Bagging\n",
    "   - Boosting\n",
    "   - Reduce variance and improve stability\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78463df8-137c-4244-9c82-cc45f64589d8",
   "metadata": {},
   "source": [
    "## 4. Cross Validation Workflow (K-Fold)\n",
    "\n",
    "- Dataset is divided into **K folds**\n",
    "- For each iteration:\n",
    "  - K−1 folds → training\n",
    "  - 1 fold → validation\n",
    "- Process is repeated K times\n",
    "- Final performance:\n",
    "  - Mean of validation scores\n",
    "  - Variance of validation scores\n",
    "\n",
    "### Interpretation\n",
    "- High variance in validation score → Overfitting\n",
    "- Low variance + good mean score → Better generalized model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeefbd3e-4ff5-4628-8353-ca4c8ac7569f",
   "metadata": {},
   "source": [
    "## 5. Model Selection after Cross Validation\n",
    "\n",
    "After CV:\n",
    "- Compare **mean training score** vs **mean validation score**\n",
    "- Identify:\n",
    "  - Underfitted models\n",
    "  - Overfitted models\n",
    "  - Well-generalized models\n",
    "- Final selected model is evaluated **once** on test data\n",
    "- Test data is never used during tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fbbbf-9092-4e3d-bbfd-02e9eabffc8e",
   "metadata": {},
   "source": [
    "## 6. Hyperparameters vs Parameters\n",
    "\n",
    "### Parameters\n",
    "- Learned during training\n",
    "- Example:\n",
    "  - Weights in Linear Regression\n",
    "  - Tree split thresholds\n",
    "\n",
    "### Hyperparameters\n",
    "- Set **before training**\n",
    "- Control model complexity and learning behavior\n",
    "- Examples:\n",
    "  - `k` in KNN\n",
    "  - `max_depth` in Decision Tree\n",
    "  - Regularization strength\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796b46a-5381-46b2-a613-48448c3e9ad0",
   "metadata": {},
   "source": [
    "## 7. What is Hyperparameter Tuning?\n",
    "\n",
    "Hyperparameter tuning is the process of **systematically changing hyperparameters**\n",
    "to:\n",
    "\n",
    "- Improve generalization\n",
    "- Control overfitting and underfitting\n",
    "- Select the best model configuration for a given dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6671ec-d346-423a-9fcf-abf22022895f",
   "metadata": {},
   "source": [
    "## 8. Why Hyperparameter Tuning is Required\n",
    "\n",
    "Hyperparameter tuning helps in:\n",
    "1. Finding a generalized model\n",
    "2. Model selection\n",
    "3. (Rarely) Feature selection indirectly\n",
    "\n",
    "Different hyperparameter values result in models with **different capacity and behavior**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b2b06-37ff-4750-bdfe-db70527892da",
   "metadata": {},
   "source": [
    "## 9. Types of Hyperparameter Tuning\n",
    "\n",
    "### 1. Manual Search\n",
    "- Manually try different hyperparameter combinations\n",
    "- Simple but inefficient\n",
    "- Not scalable\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Grid Search\n",
    "- Exhaustive search over all combinations\n",
    "- Hyperparameters are defined as a grid\n",
    "- Guarantees best result within grid\n",
    "- Computationally expensive\n",
    "- Number of experiments grows exponentially\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Random Search\n",
    "- Hyperparameters sampled randomly from ranges\n",
    "- More efficient than grid search\n",
    "- Works well when only a few hyperparameters matter\n",
    "- Still inefficient for very large search spaces\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c66af-5070-4919-a34d-26d4d9f1d05f",
   "metadata": {},
   "source": [
    "## 10. Limitations of Grid & Random Search\n",
    "\n",
    "- Computationally expensive\n",
    "- Evaluates many poor configurations\n",
    "- Inefficient for:\n",
    "  - Large datasets\n",
    "  - Complex models\n",
    "  - Deep learning models\n",
    "- Motivation for **Sequential / Bayesian Optimization**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfbffd-050e-49f0-9600-19b05b535e92",
   "metadata": {},
   "source": [
    "## 11. Sequential Search (Bayesian Optimization)\n",
    "\n",
    "### Core Idea\n",
    "- Instead of searching blindly, learn from past trials\n",
    "- Select next hyperparameter configuration **intelligently**\n",
    "\n",
    "### Key Components\n",
    "1. Small initial random sample of configurations\n",
    "2. Evaluate model performance\n",
    "3. Fit a **surrogate model**\n",
    "4. Use surrogate to propose better configurations\n",
    "5. Repeat until convergence or budget exhausted\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a93f97-65cb-4486-a075-699d76d71453",
   "metadata": {},
   "source": [
    "## 12. Surrogate Model Concept\n",
    "\n",
    "- Surrogate model approximates:\n",
    "  - Hyperparameters → Performance mapping\n",
    "- Cheaper to evaluate than training full ML model\n",
    "- Guides search toward promising regions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47566bf-b5a9-4304-8711-a98b56cb8a6f",
   "metadata": {},
   "source": [
    "## 13. Tree-Structured Parzen Estimator (TPE)\n",
    "\n",
    "- A popular Bayesian Optimization algorithm\n",
    "- Used by **Optuna**\n",
    "- Models:\n",
    "  - Good hyperparameter distributions\n",
    "  - Bad hyperparameter distributions\n",
    "- Selects new configurations that maximize expected improvement\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3f688-60aa-423e-a17f-d4e3d008a6e9",
   "metadata": {},
   "source": [
    "## 14. Why Bayesian Optimization is Efficient\n",
    "\n",
    "- Requires fewer trials\n",
    "- Avoids evaluating poor configurations\n",
    "- Suitable for:\n",
    "  - Large search spaces\n",
    "  - Expensive models\n",
    "  - Real-world ML workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f82109-e02c-43d7-9671-a5d563b52f67",
   "metadata": {},
   "source": [
    "## 15. Introduction to Optuna\n",
    "\n",
    "Optuna is a modern hyperparameter optimization framework that:\n",
    "- Implements Bayesian Optimization\n",
    "- Uses TPE by default\n",
    "- Is fast, flexible, and scalable\n",
    "- Widely used in industry and research\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e527cb-2352-4a3e-b96e-62bb539dffc4",
   "metadata": {},
   "source": [
    "## 16. Optuna Hyperparameter Tuning Workflow\n",
    "\n",
    "### Step 1: Define Objective Function\n",
    "- Written in Python\n",
    "- Includes:\n",
    "  - Hyperparameter search space\n",
    "  - Model training\n",
    "  - Evaluation metric\n",
    "- Returns a single score to optimize\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Create a Study\n",
    "- Study defines:\n",
    "  - Optimization direction (maximize / minimize)\n",
    "  - Sampler (TPE by default)\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Optimize\n",
    "- Optuna runs multiple trials\n",
    "- Each trial:\n",
    "  - Chooses hyperparameters\n",
    "  - Trains model\n",
    "  - Evaluates performance\n",
    "- Best parameters are tracked automatically\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5b9fb-746a-4c59-9496-c3193acdb483",
   "metadata": {},
   "source": [
    "## 17. Optuna Search Components\n",
    "\n",
    "- **Search Space** → Hyperparameters & their ranges\n",
    "- **Sampler** → Strategy to select next configuration\n",
    "- **Model** → ML algorithm being tuned\n",
    "- **Metric** → Performance measure\n",
    "- **Trials** → Number of optimization steps\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4964d8b-effc-43cf-9672-15ef5637fa85",
   "metadata": {},
   "source": [
    "## 18. Models Used in This Notebook\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**\n",
    "  - Hyperparameters:\n",
    "    - `n_neighbors`\n",
    "    - `weights`\n",
    "\n",
    "- **Decision Tree**\n",
    "  - Hyperparameters:\n",
    "    - `max_depth`\n",
    "    - `min_samples_split`\n",
    "    - `min_samples_leaf`\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf4867-7eff-4bc9-8d15-386cf6412968",
   "metadata": {},
   "source": [
    "## 19. Dataset Used\n",
    "\n",
    "- **Breast Cancer Wisconsin Dataset**\n",
    "- Binary classification problem\n",
    "- Used to compare tuning effectiveness across models\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3feefa-c928-42d1-89a1-e8f2ec84246c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T18:34:07.924083Z",
     "iopub.status.busy": "2026-01-09T18:34:07.923080Z",
     "iopub.status.idle": "2026-01-09T18:34:07.945615Z",
     "shell.execute_reply": "2026-01-09T18:34:07.944196Z",
     "shell.execute_reply.started": "2026-01-09T18:34:07.924083Z"
    }
   },
   "source": [
    "## 20. Key Learnings from Day 24\n",
    "\n",
    "- Grid and Random Search do not scale well\n",
    "- Bayesian Optimization is more efficient and intelligent\n",
    "- Hyperparameter tuning is essential for generalization\n",
    "- Optuna simplifies advanced tuning workflows\n",
    "- Sequential optimization reduces computational cost\n",
    "- Modern ML requires efficient model selection strategies\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfa500-10d3-4b9f-a376-8017786d146e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
